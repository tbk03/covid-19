---
title: "cornavirus-cases_latest"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(gtools)
library(testthat)
library(ggplot2)
library(tidyverse)
library(httr)
library(DBI)
library(lubridate)
library(ggrepel)
library(RcppRoll)
```
## Goals

* To understand the data available from cornavirus.data.gov.uk - what it can and can't tell you ()

https://theconversation.com/why-are-coronavirus-rates-rising-in-some-areas-of-england-and-not-others-147160


**Ideas to followup:**

* Faceting or grouping by indicies of multiple deprivation
* Variation of hospital statistics
* Co-variation specimen and report date
* Group LAs by newcase at end of lockdown ...

## Setup project

```{r source external files, include = FALSE}
source("r_code/gov_uk_covid_r_sdk.R", local = knitr::knit_global())
source("r_code/covid_helper_functions.R", local = knitr::knit_global())
```

```{r}
test_file("tests/test-covid_helper_functions.R")
```


```{r}
update_from_api = FALSE
```

## 1. Cronavirus datasets

### Latest cases CSV

```{r}
cases_latest <- read_csv("./Data/coronavirus-cases_latest.csv")

sample_n_from_df(cases_latest, 10)
```

```{r}
cases_latest %>% 
  select(`Area type`) %>% 
  distinct()
```


### Restrictions data

Restrictions data (07/10/2020) - https://visual.parliament.uk/research/visualisations/coronavirus-restrictions-map/ 



```{r}
restrictions <- read_csv("./Data/commonslibrary-coronavirus-restrictions-data.csv")

restrictions_local <- restrictions %>% 
  filter(l_restrictions == "Local") %>% 
  select(-l_url_local, -l_url_national, -l_restrictions) %>% 
  select(-starts_with("l_national")) %>% 
  rename(l_ltla = l_Category)

str_sub(colnames(restrictions_local), 1, 2) <- ""

restrictions_tidy <- restrictions_local %>%
  pivot_longer(cols = local_ruleofsix:local_openinghours, names_to = "restriction_type", values_to = "in_force")

restrictions_tidy 
```
Based on the prominent narrative that a fragmented patchwork of local measures is in place course the UK, I was expecting to observe an accompanying degree of variability in the data. However, the frequency counts for each of the local measures indicate otherwise.
```{r}
restrictions_tidy %>% 
  group_by(restriction_type) %>% 
  summarise(n = n()) 

```
So, I took a quick look at how many distinct combinations of local measures were present in the data.
```{r}
restrictions_local %>% 
  select(starts_with("local_")) %>% 
  distinct()
```

Three groups of local measures can be identified from the data: 

1 - local_householdmixing only
2 - local_householdmixing and local_businessclosures
3 - local_householdmixing and local_stayinglocal

The frequency counts for each of these three groups are show below. 

```{r}
restriction_local <- restrictions_local %>%
  unite(rest_group, starts_with(("local_"))) %>% 
  group_by(rest_group) %>% 
  mutate(rest_group_id = group_indices()) %>%
  ungroup() 

restriction_local %>% 
  group_by(rest_group_id) %>% 
  summarise(n = n())
```



**Interim conclusion:** At the level of granularity presented in this data there is little variability in the local measures in place

```{r}
la_lookup <- read_csv("./Data/Lower_Tier_Local_Authority_to_Upper_Tier_Local_Authority__December_2019__Lookup_in_England_and_Wales.csv")

restriction_local %>% 
  left_join(la_lookup, by = c("ltla" = "LTLA19NM"))
```

### Latest cases API

National only data 

* `hospitalCases`



```{r}
# Create filters:
query_filters <- c(
    "areaType=ltla"
)

# Create the structure as a list or a list of lists:
query_structure <- list(
    # areaType  = "areaType",
    areaName = "areaName",
    areaCode = "areaCode",
    date = "date",
    newCasesByPublishDate = "newCasesByPublishDate",
    cumCasesByPublishDate = "cumCasesByPublishDate",
    cumCasesBySpecimenDateRate = "cumCasesBySpecimenDateRate",
    newCasesBySpecimenDate = "newCasesBySpecimenDate",
    cumCasesBySpecimenDate = "cumCasesBySpecimenDate",
    maleCases = "maleCases",
    femaleCases = "femaleCases",
    #newPillarOneTestsByPublishDate = "newPillarOneTestsByPublishDate",
    # cumPillarOneTestsByPublishDate = "cumPillarOneTestsByPublishDate",
    # newPillarTwoTestsByPublishDate = "newPillarTwoTestsByPublishDate",
    # cumPillarTwoTestsByPublishDate = "cumPillarTwoTestsByPublishDate",
    # newPillarThreeTestsByPublishDate = "newPillarThreeTestsByPublishDate",
    # cumPillarThreeTestsByPublishDate = "cumPillarThreeTestsByPublishDate",
    # newPillarFourTestsByPublishDate = "newPillarFourTestsByPublishDate",
    # cumPillarFourTestsByPublishDate = "cumPillarFourTestsByPublishDate",
    newAdmissions = "newAdmissions",
    cumAdmissions = "cumAdmissions",
    cumAdmissionsByAge = "cumAdmissionsByAge",
    # cumTestsByPublishDate = "cumTestsByPublishDate",
    # newTestsByPublishDate = "newTestsByPublishDate",
    covidOccupiedMVBeds = "covidOccupiedMVBeds",
    hospitalCases = "hospitalCases",
    # plannedCapacityByPublishDate = "plannedCapacityByPublishDate",
    newDeaths28DaysByPublishDate = "newDeaths28DaysByPublishDate",
    cumDeaths28DaysByPublishDate = "cumDeaths28DaysByPublishDate",
    cumDeaths28DaysByPublishDateRate = "cumDeaths28DaysByPublishDateRate",
    newDeaths28DaysByDeathDate = "newDeaths28DaysByDeathDate",
    cumDeaths28DaysByDeathDate = "cumDeaths28DaysByDeathDate",
    cumDeaths28DaysByDeathDateRate = "cumDeaths28DaysByDeathDateRate"
)

if (update_from_api){
  
  result <- get_paginated_data(query_filters, query_structure)
  result <- as_tibble(result)
  
  cases_latest_db <- dbConnect(RSQLite::SQLite(), "cases_latest_db.sqlite")
  dbWriteTable(cases_latest_db, "cases", result, overwrite = TRUE)
  
  dbDisconnect(cases_latest_db)
}


```

```{r}

cases_latest_db <- dbConnect(RSQLite::SQLite(), "cases_latest_db.sqlite")

  
cases <- as_tibble(dbGetQuery(cases_latest_db, "SELECT * FROM cases"))
dbDisconnect(cases_latest_db)
  
cases <- cases %>% 
  mutate(date = as_date(date))

cases %>% 
  sample_n(10)

```

Drop columns where all values are NA

```{r}
cases <- cases %>% 
  select_if(~sum(!is.na(.)) > 0)
cases
```
Calculate moving averages

```{r}
cases <- cases %>% 
  mutate(mm_newCasesBySpecimenDate = roll_mean(newCasesBySpecimenDate, n = 7, align="center", fill = 0))

cases
```


### Population data
https://www.ons.gov.uk/peoplepopulationandcommunity/populationandmigration/populationestimates/datasets/populationestimatesforukenglandandwalesscotlandandnorthernireland

```{r}
pop_df <-read_csv("./Data/ons_mid_2019_population_estimates.csv")
pop_df <- pop_df %>% 
  rename(all_ages = `All ages`)
pop_df
```



## Exploratory data analysis

```{r}
cases %>% 
  filter(areaName == "Leeds") %>% 
  
  ggplot(aes(x = date, y = newCasesBySpecimenDate)) +
  
  geom_col() +
  geom_smooth(se = FALSE)


```

Plotting lines for confirmed cases for each (lower tier) local authority in England and Wales. Highlighting the growth in confirmed cases from August onwards, and the variability in the number of cases across the local authorities. The darker areas of the plot give an initial indication of where there are greater numbers of local authorities with similar case numbers.

```{r}
p <- ggplot(data = cases,
            mapping = aes(x = date,
                          y = newCasesBySpecimenDate,
                          group = areaName)
            )

p + geom_line(alpha = 0.1) +
  
  scale_x_date(date_breaks = "1 month",
               date_labels = "%b") +
  
  labs(x = NULL,
       y = "New Cases (by specimen date)"
       ) +
  
  theme_minimal()
```
Use newcases moving mean (1 week)
```{r}
p <- ggplot(data = cases,
            mapping = aes(x = date,
                          y = mm_newCasesBySpecimenDate,
                          group = areaName)
            )

p + geom_line(alpha = 0.1) +
  
  scale_x_date(date_breaks = "1 month",
               date_labels = "%b") +
  
  labs(x = NULL,
       y = "New Cases (by specimen date)"
       ) +
  
  theme_minimal()
```

```{r}
p <- ggplot(data = cases,
            mapping = aes(x = date,
                          y = cumCasesBySpecimenDateRate,
                          group = areaName)
            )

p + geom_line(alpha = 0.1) +
  
  scale_x_date(date_breaks = "1 month",
               date_labels = "%b") +
  
  labs(x = NULL,
       y = "Rate of cumulative cases by publish date per 100k resident population"
       ) +
  
  theme_minimal()
```
To look at new cases per 100,000 population, make use of ONS population date

```{r}
pop_df_minimal <- pop_df %>% 
  select(Code, all_ages)

pop_df_minimal
```
Noticed negative newCase numbers, resulting in negative rates

```{r}
cases_pop <- cases %>%
  left_join(pop_df_minimal, by = c("areaCode" = "Code")) %>% 
  mutate(newCasesBySpecimenDateRate = (newCasesBySpecimenDate / all_ages) * 1e05)

sample_n_from_df(cases_pop, 10)
```

```{r}
p <- ggplot(data = cases_pop,
            mapping = aes(x = date,
                          #y = newCasesBySpecimenDateRate,
                          y = roll_mean(newCasesBySpecimenDateRate, n =7, align = "center", fill = 0),
                          group = areaName)
            )

p + geom_line(alpha = 0.1) +
  
  scale_x_date(date_breaks = "1 month",
               date_labels = "%b") +
  
  labs(x = NULL,
       y = "Rate of new cases per day per 100k resident population"
       ) +
  
  theme_minimal()
```
Look at a two window centred on 1st July - around the minimum

```{r}
july_first_case_summary <- cases_pop %>%
  filter(date >= "2020-06-24") %>% 
  filter(date <= "2020-07-08") %>%
  group_by(areaName) %>% 
  summarise(mean_new_case_rate_jul1 = mean(newCasesBySpecimenDateRate))
  #mutate(quantile = quantcut(mean_new_case_rate, na.rm = TRUE)) %>% 

july_first_case_summary %>% 
  ggplot(mapping = aes(x = mean_new_case_rate_jul1)) +
  
  geom_histogram(bins = 100) +
  
  theme_minimal()


```

```{r}
summary(july_first_case_summary)
```

```{r, fig.height=12, fig.width = 8}
july_first_case_summary <- july_first_case_summary %>% 
  mutate(quantile_new_case_rate_jul1 = quantcut(mean_new_case_rate_jul1, na.rm = TRUE))

cases_pop <- cases_pop %>% 
  left_join(july_first_case_summary)

facet_labs <- c(`[0,0.269]` = "q1", `(0.269,0.524]` = "q2", `(0.524,0.941]` = "q3", `(0.941,18.3]` = "q4")

p <- ggplot(data = subset(cases_pop, !is.na(quantile_new_case_rate_jul1)),
            mapping = aes(x = date,
                          y = roll_mean(newCasesBySpecimenDateRate, n = 7, align = "center", fill = 0),
                          group = areaName,
                          colour = quantile_new_case_rate_jul1
                          )
            )

p + geom_line(alpha = 0.3) +
  
  facet_wrap(~quantile_new_case_rate_jul1, ncol = 1, 
             labeller=labeller(quantile_new_case_rate_jul1 = facet_labs)) +
  
  scale_x_date(date_breaks = "1 month",
               date_labels = "%b",
               limits =  c(as_date("2020-07-01"), NA)             
               ) +
  
  labs(x = NULL,
       y = "Rate of new cases per day per 100k resident population"
       ) +

  theme_minimal() +
  theme(legend.position = "none")
```


### September

Let's take a look at the variability in case numbers across local authorities across September.

Labeled with grey text - local authorities without restrictions, and amongst the 50 local authorities with the highest rates.
Labeled with light blue text - the one local authority subject to business closures.

```{r, fig.width=12, fig.height=8}

sept_cases <- cases_pop %>% 
  filter(date >= as_date("2020-09-01")) %>% 
  filter(date < as_date("2020-10-01")) %>% 
  
  # remove Scotland data from case data, as restriction data for Scotland is not available
  filter(!str_detect(areaCode, "^S")) %>% 
  
  left_join(restriction_local, by = c("areaName" = "ltla")) %>% 
  
  group_by(areaName) %>% 
  summarise(sept_new_cases_by_specimen_date = sum(newCasesBySpecimenDate),
            mean_case_rate = mean(newCasesBySpecimenDateRate),
            restrictions = median(rest_group_id, na.rm = TRUE)
            ) %>% 
  mutate(mean_case_rate_rank = min_rank(desc(mean_case_rate)))

sept_cases$restrictions[is.na(sept_cases$restrictions)] <- 0
sept_cases$restrictions <- as_factor(sept_cases$restrictions)

ggplot(data = sept_cases, mapping = aes(x = reorder(areaName, mean_case_rate),
                                        y = mean_case_rate)
       ) +
  
  geom_col(aes(fill = restrictions), alpha = 0.8) +
  geom_text_repel(data = subset(sept_cases, restrictions == 2),
                  mapping = aes(label = areaName),
                  nudge_x = -20,
                  nudge_y = 5,
                  colour = "#56B4E9"
                  ) +
  
    geom_text_repel(data = subset(sept_cases, 
                                  restrictions == 0 & mean_case_rate_rank <= 50
                                  ),
                  mapping = aes(label = areaName),
                  nudge_x = -25,
                  nudge_y = 5,
                  colour = "grey60"
                  ) +
  
  scale_x_discrete(labels = NULL) +
  scale_fill_manual(values=c("grey60", "aquamarine3", "#56B4E9", "blue4"), 
                    labels = c("None", "Household mixing", "House mixing and business closures", "Household mixing and stay local" )
                    ) +
  
  labs(x = "Local authorities (Exc. Scotland)",
       y = "Mean new cases per day per 100k resident population (Sept. 2020)",
       fill = "Restrictions",
       caption = "Local authorities excluding Scotland") +
  
  theme_minimal() +
  theme(panel.grid.major.x = element_blank())

# ggplot(data = sept_cases, mapping = aes(x = newCasesBySpecimenDate), group = areaName) +
#   geom_histogram(binwidth = 1) +
#   
#   scale_x_continuous(limits = c(0,100)) +
#   
#   theme_minimal()

```



## Covariation

```{r}
head(cases)
```


```{r}
p <- ggplot(data = cases, mapping = aes(x = newCasesBySpecimenDate, y = newCasesByPublishDate))

p + geom_jitter()
```



*Scatter plot cases vs deaths
