---
title: "cornavirus-cases_latest"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(testthat)
library(ggplot2)
library(tidyverse)
library(httr)
library(DBI)
library(lubridate)
```
## Goals

* To understand the data available from cornavirus.data.gov.uk - what it can and can't tell you ()

https://theconversation.com/why-are-coronavirus-rates-rising-in-some-areas-of-england-and-not-others-147160


## Setup project

```{r source external files, include = FALSE}
source("r_code/gov_uk_covid_r_sdk.R", local = knitr::knit_global())
source("r_code/covid_helper_functions.R", local = knitr::knit_global())
```

```{r}
test_file("tests/test-covid_helper_functions.R")
```


```{r}
update_from_api = FALSE
```

## 1. Cronavirus datasets

### Latest cases CSV

```{r}
cases_latest <- read_csv("./Data/coronavirus-cases_latest.csv")

sample_n_from_df(cases_latest, 10)
```

```{r}
cases_latest %>% 
  select(`Area type`) %>% 
  distinct()
```


### Restrictions data

Restrictions data - https://visual.parliament.uk/research/visualisations/coronavirus-restrictions-map/ 



```{r}
restrictions <- read_csv("./Data/commonslibrary-coronavirus-restrictions-data.csv")

restrictions_local <- restrictions %>% 
  filter(l_restrictions == "Local") %>% 
  select(-l_url_local, -l_url_national, -l_restrictions) %>% 
  select(-starts_with("l_national")) %>% 
  rename(l_ltla = l_Category)

str_sub(colnames(restrictions_local), 1, 2) <- ""

restrictions_tidy <- restrictions_local %>%
  pivot_longer(cols = local_ruleofsix:local_openinghours, names_to = "restriction_type", values_to = "in_force")

restrictions_tidy 
```
Based on the prominent narrative that a fragmented patchwork of local measures is in place course the UK, I was expecting to observe an accompanying degree of variability in the data. However, the frequency counts for each of the local measures indicate otherwise.
```{r}
restrictions_tidy %>% 
  group_by(restriction_type) %>% 
  summarise(n = n()) 

```
So, I took a quick look at how many distinct combinations of local measures were present in the data.
```{r}
restrictions_local %>% 
  select(starts_with("local_")) %>% 
  distinct()
```

Three groups of local measures can be identified from the data: 

1 - local_householdmixing only
2 - local_householdmixing and local_businessclosures
3 - local_householdmixing and local_stayinglocal

The frequency counts for each of these three groups are show below. 

```{r}
restriction_local <- restrictions_local %>%
  unite(rest_group, starts_with(("local_"))) %>% 
  group_by(rest_group) %>% 
  mutate(rest_group_id = group_indices()) %>%
  ungroup() 

restriction_local %>% 
  group_by(rest_group_id) %>% 
  summarise(n = n())
```

**Interim conclusion:** At the level of granularity presented in this data there is little variability in the local measures in place

```{r}
la_lookup <- read_csv("./Data/Lower_Tier_Local_Authority_to_Upper_Tier_Local_Authority__December_2019__Lookup_in_England_and_Wales.csv")

restriction_local %>% 
  left_join(la_lookup, by = c("ltla" = "LTLA19NM"))
```

### Latest cases API

National only data 

* `hospitalCases`



```{r}
# Create filters:
query_filters <- c(
    "areaType=ltla"
)

# Create the structure as a list or a list of lists:
query_structure <- list(
    # areaType  = "areaType",
    areaName = "areaName",
    areaCode = "areaCode",
    date = "date",
    #newCasesByPublishDate = "newCasesByPublishDate",
    #cumCasesByPublishDate = "cumCasesByPublishDate",
    cumCasesBySpecimenDateRate = "cumCasesBySpecimenDateRate",
    newCasesBySpecimenDate = "newCasesBySpecimenDate",
    cumCasesBySpecimenDate = "cumCasesBySpecimenDate",
    maleCases = "maleCases",
    femaleCases = "femaleCases",
    #newPillarOneTestsByPublishDate = "newPillarOneTestsByPublishDate",
    # cumPillarOneTestsByPublishDate = "cumPillarOneTestsByPublishDate",
    # newPillarTwoTestsByPublishDate = "newPillarTwoTestsByPublishDate",
    # cumPillarTwoTestsByPublishDate = "cumPillarTwoTestsByPublishDate",
    # newPillarThreeTestsByPublishDate = "newPillarThreeTestsByPublishDate",
    # cumPillarThreeTestsByPublishDate = "cumPillarThreeTestsByPublishDate",
    # newPillarFourTestsByPublishDate = "newPillarFourTestsByPublishDate",
    # cumPillarFourTestsByPublishDate = "cumPillarFourTestsByPublishDate",
    newAdmissions = "newAdmissions",
    cumAdmissions = "cumAdmissions",
    cumAdmissionsByAge = "cumAdmissionsByAge",
    # cumTestsByPublishDate = "cumTestsByPublishDate",
    # newTestsByPublishDate = "newTestsByPublishDate",
    covidOccupiedMVBeds = "covidOccupiedMVBeds",
    hospitalCases = "hospitalCases",
    # plannedCapacityByPublishDate = "plannedCapacityByPublishDate",
    newDeaths28DaysByPublishDate = "newDeaths28DaysByPublishDate",
    cumDeaths28DaysByPublishDate = "cumDeaths28DaysByPublishDate",
    cumDeaths28DaysByPublishDateRate = "cumDeaths28DaysByPublishDateRate",
    newDeaths28DaysByDeathDate = "newDeaths28DaysByDeathDate",
    cumDeaths28DaysByDeathDate = "cumDeaths28DaysByDeathDate",
    cumDeaths28DaysByDeathDateRate = "cumDeaths28DaysByDeathDateRate"
)

if (update_from_api){
  
  result <- get_paginated_data(query_filters, query_structure)
  result <- as_tibble(result)
  
  cases_latest_db <- dbConnect(RSQLite::SQLite(), "cases_latest_db.sqlite")
  dbWriteTable(cases_latest_db, "cases", result, overwrite = TRUE)
  
  dbDisconnect(cases_latest_db)
}


```

```{r}

cases_latest_db <- dbConnect(RSQLite::SQLite(), "cases_latest_db.sqlite")

  
df <- as_tibble(dbGetQuery(cases_latest_db, "SELECT * FROM cases"))
dbDisconnect(cases_latest_db)
  
df <- df %>% 
  mutate(date = as_date(date))

df %>% 
  sample_n(10)

```

Drop columns where all values are NA

```{r}
df <- df %>% 
  select_if(~sum(!is.na(.)) > 0) %>% 
  select(-cumCasesBySpecimenDateRate.1)
df
```


```{r}
df %>% 
  filter(areaName == "Leeds") %>% 
  
  ggplot(aes(x = date, y = newCasesBySpecimenDate)) +
  
  geom_col() +
  geom_smooth(se = FALSE)


```

Plotting lines for confirmed cases for each (lower tier) local authority in England and Wales. Highlighting the growth in confirmed cases from August onwards, and the variability in the number of cases across the local authorities. The darker areas of the plot give an initial indication of where there are greater numbers of local authorities with similar case numbers.

```{r}
p <- ggplot(data = df,
            mapping = aes(x = date,
                          y = newCasesBySpecimenDate,
                          group = areaName)
            )

p + geom_line(alpha = 0.1) +
  
  scale_x_date(date_breaks = "1 month",
               date_labels = "%b") +
  
  labs(x = NULL,
       y = "New Cases (by specimen date)"
       ) +
  
  theme_minimal()
```

Let's take a look at the variablity in case numbers across local authorities across September

```{r, out.width="150%"}

sept_cases <- df %>% 
  filter(date >= as_date("2020-09-01")) %>% 
  filter(date < as_date("2020-10-01")) %>% 
  
  # remove Scotland data from case data, as restriction data for Scotland is not available
  filter(!str_detect(areaCode, "^S")) %>% 
  
  left_join(restriction_local, by = c("areaName" = "ltla")) %>% 
  
  group_by(areaName) %>% 
  summarise(sept_new_cases_by_specimen_date = sum(newCasesBySpecimenDate),
            restrictions = as_factor(median(rest_group_id, na.rm = TRUE))
            )

sept_cases

ggplot(data = sept_cases, mapping = aes(x = reorder(areaName, sept_new_cases_by_specimen_date),
                                        y = sept_new_cases_by_specimen_date)
       ) +
  geom_col(aes(fill = restrictions)) +
  
  scale_fill_discrete() +
  
  theme_minimal()

# ggplot(data = sept_cases, mapping = aes(x = newCasesBySpecimenDate), group = areaName) +
#   geom_histogram(binwidth = 1) +
#   
#   scale_x_continuous(limits = c(0,100)) +
#   
#   theme_minimal()

```

