---
title: "green space EDA 2"
output: 
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, echo=FALSE, message=FALSE}
library(tidyverse)
library(readxl)
library(purrr)
library(corrplot)

source("r_code/covid_helper_functions.R")

`%nin%` = Negate(`%in%`)

theme_set(theme_light())
```
Objectives:

* personal interest in the topic
+ green gym
+ covid experience

https://blogs.bmj.com/bmj/2020/07/03/covid-19-has-highlighted-the-inadequate-and-unequal-access-to-high-quality-green-spaces/
https://www.weforum.org/agenda/2020/08/parks-green-spaces-mental-health-access-equality/

* Develop 


Scale of analysis: Local Authority District (the finest geographic granularity available for all datasets)
Geographic scope: England (case data at MSOA level available for England only)

## 1. Import and tidy data sources

### 1.1. Access to private green space (gardens)
The ONS (Office for National Statistics) provides [data on access to private green space](https://www.ons.gov.uk/economy/environmentalaccounts/datasets/accesstogardensandpublicgreenspaceingreatbritain) (i.e. access to gardens) for each Local Authority District in Great Britain. Here I am using the most recent April 2020 edition of the data. I quickly, manually edited the ONS excel file to make it easier use the `read_excel` function for data import. Given it is unlikely that the ONS data will be updated during the course of this analysis, it was preferable to go for the quicker manual process than investing time in a re-producible programmatic approach.

```{r, import gs 1}

gardens <- read_excel("./Data/osprivateoutdoorspacereferencetables.xlsx", sheet = "LAD gardens_2")
gardens %>% 
  sample_n_from_df(10)
```

### 1.2. Access to public green space (parks)
The ONS (Office for National Statistics) also provides [data on access to public green space](https://www.ons.gov.uk/economy/environmentalaccounts/datasets/accesstogardensandpublicgreenspaceingreatbritain) (i.e. access to parks and playing fields) for each Local Authority District in Great Britain. In this case no manual editing of the ONS excel file was required. 

```{r, import gs 2}
parks <-  read_excel("./Data/ospublicgreenspacereferencetables.xlsx", sheet = "LAD Parks only")
parks %>% 
  sample_n_from_df(10)
```

### 1.3. Covid cases
[data.gov.uk](https://coronavirus.data.gov.uk/details/download) provides data on the number of Covid-19 cases (as confirmed by positive tests) occurring in each English Local Authority District. 

```{r, import covid 1, message=FALSE}
covid_cases <- read_csv("./Data/ltla_2020-12-08.csv")
                  
covid_cases %>% 
  sample_n_from_df(10)

```


## 1.5. Population data
The ONS also provides [data](https://www.ons.gov.uk/peoplepopulationandcommunity/populationandmigration/populationestimates/datasets/populationestimatesforukenglandandwalesscotlandandnorthernireland) esitmating the populations resident in Local Authority District. This will be helpful later on when  

```{r}
populations <- read_csv("./Data/ons_mid_2019_population_estimates.csv")
populations

```

## 2. Transform datasets for analysis

### 2.1. Focus down on variables of interest

*Private green space: * The ONS provides data on private green space separately for flats and house, additionally totals (including both flats and houses) are provided. In this case just the totals are likely to be of interest, as I am not expecting to distinguish between types of housing stock in the analysis the relationship between access to green space and Covid-19 case numbers.

```{r}
gardens <- gardens %>% 
  filter(`Country name` == "England") %>% 
  select(`LAD code`, `LAD name`, `T_Address count`, 
         `T_Percentage of adresses with private outdoor space`, 
         `T_Average size of private outdoor space (m2)`
         ) %>% 
  rename(address_count = `T_Address count`,
         perc_with_garden = `T_Percentage of adresses with private outdoor space`,
         ave_garden_size = `T_Average size of private outdoor space (m2)`
         )

gardens
```
*Public green space: * the parks dataset is more straightforward (than the garden's dataset), so I just drop some redudant geographic variables.

```{r}
parks <- parks %>% 
  filter(`Country name` == "England") %>% 
  select(-`Country code`, -`Country name`, -`Region code`, -`Region name`)

parks
```


*Covid_19_cases: * 

* There are 27030 NAs and 21372 zeros in the new_case column. If a NA value for new case is different to a zero value? How can this best be managed ni the analysis below? For now I'll assume an NA can be treated as zero, given there is no documentation on coronavirus.data.gov.uk providing details.
* the number of cases (confirmed by a positive test result) in each Local Authority are given on a daily basis.

```{r}
covid_cases <- covid_cases %>%
  filter(str_detect(areaCode, "^E")) %>% 
  select(-areaType, -newCasesBySpecimenDateRollingSum, -newCasesBySpecimenDateRollingRate) %>% 
  rename(new_cases = newCasesBySpecimenDate)

covid_cases

summary(covid_cases)

covid_cases %>% 
  count(new_cases) %>% 
  head(1)
```
*Population data: * 

* I am interested in the total population of each Local Authority District. So, I drop variables from the `populations` dataframe detailing the breakdown of population by age, and retain the variable for total population within a given geographic area.
```{r}
populations <- populations %>% 
  select(Code, Name, `All ages`) %>% 
  rename(population = `All ages`)

populations
```


### 2.2. Join datasets
Having identified the variables of interest across the four datasets imported above (gardens, parks, covid_cases and populations), I merge these together to form a single dataframe. This will hopefully make things a bit easier later on in terms of visualization, and also help keep the data wrangling processes seperate from subsequent visualization processes.

```{r}
# join the four datasets into a single dataframe
covid_gardens_parks_pop <- covid_cases %>% 
  left_join(gardens, by = c("areaCode" = "LAD code")) %>%
  select(-`LAD name`) %>% 
  left_join(parks, by = c("areaCode" = "LAD code")) %>% 
  select(-`LAD name`) %>% 
  left_join(populations, by = c("areaCode" = "Code")) %>% 
  select(-Name)

```

I then quickly check to see if NA values have been introduced through the joins performed above And, it appears they have. I am not  concerned about the NAs for the `new_cases` variable at this stage, as I've considered these above. 

```{r}

# check how many NAs occur in each column
covid_gardens_parks_pop %>%
  summarise(across(.fns = ~ sum(is.na(.))))

```
But it does look worth checking the extent to which data relating to gardens, parks and population is missing following the join. In particular, how many Local Authorities have missing data?

```{r}
id_LAs_with_NAs <- function(df, column_name){
  
  # convert the string passed to the function for use as a column name in a dplyr function
  column_name_sym <- rlang::sym(column_name)
  
  # identify Local Authorities where an NA is present in the specified column
  df %>%
    filter(is.na(!!column_name_sym)) %>%
    distinct(areaName)
}

# select variable names of interest 
vars <- colnames(covid_gardens_parks_pop %>% 
                   select(-new_cases) # as discussed above there are many NAs for variable
                 )
# create a list of Local Authorities where there are NA entries in the parks, gardens and population datasets
LAs_with_NAs <- vars %>%
  map_df(~ id_LAs_with_NAs(covid_gardens_parks_pop, .x)) %>% 
  distinct()

LAs_with_NAs


```
As the missing data issues are restricted to just five Local Authorities, the issue with NAs appears relatively small and unlikely to adversely impact the analysis I plan to move on to below. I do however remove data for these five local authorities from the aggregated dataframe, to prevent the issue of these local authorities appearing in plot including some variables but not in plots including other variables.

```{r}
covid_gardens_parks_pop <- covid_gardens_parks_pop %>%
  filter(areaName %nin% LAs_with_NAs)
```


### 2.3. Create variables for analysis 
Data on Covid-19 cases confirmed by a positive test within each Local Authority District is recorded on a daily basis. I am trying to understand the overall extent to which each local authority has been affected by Covid-19. So, I calculated total case numbers (up to the 8th December) for each Local Authority District. Additionally, I wanted to take into account the variations in population size across different local authorities. So, I calculated the number of cases per 100,000 population (a metric often used in [government reporting](https://coronavirus.data.gov.uk/details/about-data#rate-calculations)). 

```{r}
total_cases <- covid_gardens_parks_pop %>% 
  
  # calculate total number of cases for each Local Authority District
  group_by(areaCode, areaName) %>% 
  mutate(total_cases = sum(new_cases, na.rm = T)) %>% 
  ungroup() %>% 
  
  # remove date related information and associated duplicate rows as no longer required
  select(-date, -new_cases) %>% 
  distinct() %>% 
  
  # create variables normalized for population
  mutate(cases_per_ht = total_cases / population * 1e+5,
         num_parks_per_ht = `Average number of  Parks within one km` / population * 1e+5) %>% 
  # create other variables of potential interest
  mutate(occupancy_rate = population / address_count)
total_cases
```
## 3. Visualise and interpret the data
Here I am mostly interested in identifying any associations between the green space related variables (provided by the ONS), and the rates of Covid-19 cases. So, I begin by producing  a set scatter plots, considering the green space related variables as potential explanatory variables (on the x axis), and the number of cases per 100,000 population as the response variable (on the y axis). Where each point plotted represents an individual Local Authority District.

```{r, fig.width=10}
total_cases_tidy <- total_cases %>% 
  select(-address_count, -population, - total_cases, - num_parks_per_ht, - occupancy_rate) %>% 
  pivot_longer(perc_with_garden:`Average combined size of  Parks within 1km  (m2)`,
               names_to = "explanatory_variable")
  
p1 <-  ggplot(data = total_cases_tidy,
             mapping = aes(x = value, y = cases_per_ht)
             )

p1 + geom_jitter(alpha = 0.5) +
    facet_wrap(~ explanatory_variable, scales="free")

```
From inspection of the scatter plots above, the most promising potential explanatory variables are the average garden size and the average distance to the nearest park. So, focus on these two variables in more detail.

```{r}
vars_of_interest <- c("ave_garden_size", "Average distance to nearest Park (m)")

total_cases_focus <- total_cases_tidy %>% 
  # remove green space variables I am no longer interested in
  filter(explanatory_variable %in% vars_of_interest)
  

total_cases_focus
```

Focusing on average garden size and the average distance to the nearest park, I quickly plotted each variable against cases per  100,000 population, and the log (base 10) of cases per 100,000 population. This was because in the original plots above I had noticed perhaps a hint on non-linearity in the association between the green space variables and the number of cases. Reviewing the plots with the log y scale I thought that this transformation of the data did little to bring what associations are present in better focus. And, log scales are typically less intuitive to interpret than linear scales, so I decided to skick with the linear y scales for the remainder of the analysis.

```{r}
p2 <-  ggplot(data = total_cases_focus,
             mapping = aes(x = value, y = cases_per_ht)
             )

p2 + geom_jitter(alpha = 0.5) +
    facet_wrap(~ explanatory_variable, scales="free")


p3 <-  ggplot(data = total_cases_focus,
             mapping = aes(x = value, y = log(cases_per_ht))
             )

p3 + geom_jitter(alpha = 0.5) +
    facet_wrap(~ explanatory_variable, scales="free")

```


At this point it occurred to me that it would be interesting to explore if the affluence of each Local Authority had a mediating role to play in the relationships between the two green space variables and the number of Covid-19 cases. So, I imported so some  data (again from the ONS) estimating the average salaries of people living in each local authority.

I didn't look at the NAs created by coercing the variable types to numerics. I just filtered out Local Authority with NA values for the Mean salary later on (ahead of plotting).

```{r}
income <- read_excel("./Data/PROV - Home Geography Table 8.7a   Annual pay - Gross 2020.xls",
                     sheet = "All_edit_for_import")

income <- income %>% 
  
  # mean and median variables imported as characters (perhaps something to using read_excel ...)
  mutate(Median = as.double(Median),
         Mean = as.double(Mean)
         )
```
```{r}

# taken from the same dataset as the Local Authority mean/median data
eng_median_salary <-  26055	
eng_mean_salary <- 32237

total_cases_income <- total_cases_focus %>% 
  pivot_wider(names_from = "explanatory_variable", values_from = "value") %>%
  rename(ave_dist_to_park = "Average distance to nearest Park (m)") %>% # simplifying naming of variable of interest
  left_join(income %>% 
              select(Code, Median, Mean),
            by = c("areaCode" = "Code")
            ) %>% 
  mutate(above_mean = Mean > eng_mean_salary) %>% #create variable to allow grouping in plots below
  
  # remove NAs in variables to be included in the plots
  filter(!is.na(cases_per_ht)) %>% 
  filter(!is.na(Mean))

total_cases_income
```

https://stackoverflow.com/questions/58718527/setting-midpoint-for-continuous-diverging-color-scale-on-a-heatmap

```{r}
library(colorspace)

x_label <- expression("\nAverage garden size in"~m^2)
y_label <- "Total number of confirmed Covid-19 cases\n"
subtitle <- str_c("The average salary across England as a whole in 2020 is £", eng_mean_salary, ".\n")
title <- "Average garden size and the number of Covid-19 cases\nin English Local Authorities\n"
legend_label <- "Average salary in\nthe local authority"

facet_labels <- c(`FALSE` = str_c("Local Authorities with average salaries\n equal to or below £", eng_mean_salary),
                  `TRUE` = str_c("Local Authorities with average salaries\n above £", eng_mean_salary))


# create a function for core elements of the plot, as I am making two very 
# similar plots with different variables on the x axis

green_space_covid_plot <- function(){
  
  list(geom_jitter(mapping = aes(y = cases_per_ht,
                               fill = Mean),
                 size = 2, 
                 shape = 21, 
                 colour = "grey30"),
       
       # set the midpoint of the diverging colour scale to England's mean salary
       # strengthen the starting colour for the lower half of scale 
       # (as the salary range above the mean is wider than the salary range below)
       scale_fill_continuous_divergingx(palette = 'RdBu', mid = eng_mean_salary,
                                   c1 = 0, l1 = 0, p1 = 1, p2 = 1),
       
       facet_wrap(~ above_mean, labeller = as_labeller(facet_labels)),
       
       labs(y = y_label,
            fill = legend_label,
            subtitle = subtitle)
  )
}

# create the 
p4 <-  ggplot(data = subset(total_cases_income, subset = ave_garden_size < 1000), # remove an outlier
             mapping = aes(x = ave_garden_size)
             )

p4 + green_space_covid_plot() +
  
  labs(x = x_label,
       title = title
       )
  #xlim(0, 1000) +
  
```

```{r}

x_label <- "\nAverage distance to nearest park in m"
title <- "Average distance to nearest park and the number of Covid-19 cases\nin English Local Authorities\n"

p5 <-  ggplot(data = subset(total_cases_income, subset = ave_dist_to_park < 900), # remove two outliers
             mapping = aes(x = ave_dist_to_park)
             )

p5 + green_space_covid_plot() +
  
    labs(x = x_label,
       subtitle = subtitle,
       title = title
       )
```
```{r}

```




```{r, fig.height=7.5}

total_cases_corr <- total_cases_focus %>% 
  pivot_wider(names_from = "explanatory_variable", values_from = "value") %>%
  rename(ave_dist_to_park = "Average distance to nearest Park (m)") %>%
  mutate(log_ave_garden_size = log(ave_garden_size),
         log_ave_dist_to_park = log(ave_dist_to_park)
         ) %>% 
  select(cases_per_ht:log_ave_dist_to_park) %>% 
  drop_na()

corrlation_matrix <- cor(total_cases_corr)

corrplot(corrlation_matrix, method = "circle", type = 'lower')
corrplot(corrlation_matrix, method = "number", type = 'lower')
```


```{r}
cor(x = total_cases$ave_garden_size, y = total_cases$total_cases, use="complete.obs")

cor(x = total_cases$`Average number of  Parks within one km`, y = total_cases$total_cases, use="complete.obs")

cor(x = total_cases$`Average distance to nearest Park (m)`, y = total_cases$total_cases, use="complete.obs")

```




```{r}




# p <- ggplot(data = total_cases,
#             mapping = aes(x = `Average distance to nearest Park (m)`,
#                           y = cases_per_ht)
#             )
# 
# p + geom_jitter()

```

```{r}

p <- ggplot(data = total_cases,
            mapping = aes(x = ave_garden_size,
                          y = log(cases_per_ht))
            )

p + geom_jitter()

```

## 4. Conclusions


## 2. Identifying variables of interest

### 2.1. Private green space

two sub groups (Flats and Houses) within the data, at this stage interested in both (also provided)

```{r}
priv_gs_focus <- private_green_space %>% 
  select(`LAD code`, `LAD name`, `T_Address count`, 
         `T_Percentage of adresses with private outdoor space`,
         `T_Average size of private outdoor space (m2)`
         ) %>% 
  rename(address_count = `T_Address count`,
         perc_garden = `T_Percentage of adresses with private outdoor space`,
         ave_garden_size = `T_Average size of private outdoor space (m2)`)


priv_gs_focus

```
```{r, echo=FALSE, message=FALSE}
num_NA <- priv_gs_focus %>% 
  map(~ sum(is.na(.x))) %>% 
  as_tibble() %>% 
  sum()

priv_gs_focus_dim <- dim(priv_gs_focus)
```

There `r num_NA` NA values present across all columns in the `priv_gs_focus` dataframe. Given the number of NAs is small relative to the size of the dataframe (`r priv_gs_focus_dim`), and this is an exploratory data analysis I'll leave NAs to be handled/removed by the plotting functions used below.


[How to plot boxplot and histogram and align](https://stackoverflow.com/questions/58306727/perfectly-align-horizontal-boxplot-under-histogram)

```{r}

format_hist_box_pair_plot <- function(x_lims){
  list(scale_x_continuous(limits= x_lims), 
       theme_minimal()
       )
}

hist_box_pair_plot <- function(df, x_var, x_lims, x_label, y_label,
                               colour = "grey40", binwidth = 0.01, ...){
  
  histogram <- ggplot(data = df,
              mapping = aes_string(x = x_var))
  
  histogram <- histogram + geom_histogram(fill = colour, binwidth = binwidth) +
    
    labs(x = NULL, y = y_label) +
    format_hist_box_pair_plot(x_lims)
    
  box_plot <- ggplot(data = df,
              mapping = aes_string(x = x_var))
  
  box_plot <- box_plot + geom_boxplot(colour = colour) +

    scale_y_continuous(labels = NULL) +
    labs(x = x_label) +
    format_hist_box_pair_plot(x_lims)
  
  #combine and align the histogram and box plot
  cowplot::plot_grid(histogram, box_plot,
                     ncol = 1, rel_heights = c(3, 1),
                     align = 'v', axis = 'lr')
}

hist_box_pair_plot(priv_gs_focus, "perc_garden",
                   x_label = "Percentage of adresses with private outdoor space",
                   y_label = "number of Local Authority Districts",
                   x_lims = c(0, 1)
                   ) 

```
On how to pass variable names to function which wrapper around dplyr function calls https://cran.r-project.org/web/packages/dplyr/vignettes/programming.html


```{r}
 
var_summary_stats <- function(column, na.rm = TRUE) {
  # the argument column is expected to be numeric vector, as this function was designed 
  # to work with purrr::map (which passes dataframe columns as vectors to the function
  # being mapped)
  
  # return a single row dataframe containing the summary stats for column
  tibble(
    min = min(column, na.rm = na.rm),
    q1 = quantile(column, probs = 0.25, na.rm = na.rm),
    median = median(column, na.rm = na.rm),
    q3 = quantile(column, probs = 0.75, na.rm = na.rm),
    max = max(column, na.rm = na.rm),
    iqr = IQR(column, na.rm = na.rm),
    mean = mean(column, na.rm = na.rm),
    sd = sd(column, na.rm = na.rm)
  )
}

df_summary_stats <- function(df){
  
  # get the names of the numeric variables in the dataframe
  variable_name <- df %>%
    select_if(is.numeric) %>% 
    names()

  # return a dataframe containing summary stats for each numeric variable in df
  df %>%
    select_if(is.numeric) %>% 
    purrr::map_dfr(var_summary_stats) %>% 
    add_column(variable_name, .before = 1)
}
  
df_summary_stats(priv_gs_focus)

summary_functions <- list(mean = ~ mean(.x, na.rm = T), 
                          sd = ~ sd(.x, na.rm = T)
                          )

priv_gs_focus %>% 
  summarise(across(where(is_numeric), summary_functions 
                   )
            )

```


```{r}
hist_box_pair_plot(priv_gs_focus, "ave_garden_size",
                   x_label = "Average size private outdoor space (m2)",
                   y_label = "number of Local Authority Districts",
                   x_lims = c(0, 2000),
                   binwidth = 50
                   )

```


```{r}
p <- ggplot(data = priv_gs_focus,
            mapping = aes(x = log10(ave_garden_size))
            )

p + geom_histogram()
```

### 2.2. Public green space
```{r}
count_NA_in_df = function(df){
  df %>% 
    map(~ sum(is.na(.x))) %>% 
    as_tibble()
}

parks

count_NA_in_df(parks)

```


### 2.3. Covid-19 cases

```{r}
cases_focus <- cases_tidy %>% 
  select(msoa11_cd, msoa11_hclnm, week_commencing, cases) %>% 
  arrange(msoa11_cd, week_commencing) %>%
  
  group_by(msoa11_cd) %>% 
  mutate(culm_cases = cumsum(ifelse(is.na(cases), 0, cases))         )

cases_focus

count_NA_in_df(cases_focus)
  

```

calculating infections per 100,000

```{r}

#process geog lookup table
msoa_to_lad <- geog_lookup %>%
  select(MSOA11CD, MSOA11NM, LAD17CD, LAD17NM) %>% 
  # remove duplicate entries of each combination
  unique()

# process populations table
populations_minimal <- populations %>% 
  select(Code, Name, Geography1, `All ages`)

# join cases with geog lookup
cases_lad <- cases_focus %>% 
  left_join(msoa_to_lad, by = c("msoa11_cd" = "MSOA11CD")) %>%
  group_by(LAD17CD, LAD17NM) %>%
  summarise(total_cases = sum(cases, na.rm = TRUE))
  
# then join with population and calculate positive tests per 100,000 people
cases_lad_pop <- cases_lad %>%
  left_join(populations_minimal, by = c("LAD17CD" = "Code")) %>% 
  mutate(cases_per_100000_pop = (total_cases / `All ages`) * 1e+5)

# then join with private green space data
cases_lad_pop_gardens <- cases_lad_pop %>% 
  left_join(priv_gs_focus, by = c("LAD17CD" = "LAD code"))

# then join with parks data
cases_lad_pop_gardens_parks <- cases_lad_pop_gardens %>% 
  left_join(parks, by = c("LAD17CD" = "LAD code"))

# remove some redundant columns
analysis_df <- cases_lad_pop_gardens_parks %>% 
  select(-`LAD name.y`, - `LAD name.x`, - Name)

analysis_df
```

## 3. Analysing the relationships between access to green space and Covid-19 cases


### 3.2. Parks and case numbers

ONS data on access to parks is available at LSOA and LAD (Local Authority District) scales, whereas data.gov.uk Covid-19 case data is provided at the MSOA scale. Each MSOA is made up of a number of LSOAs, but it not clear how best average the variables detailing access to green space over multiple LSOAs (given that LSOAs can be different sizes in terms of population and geography). So, making the case and green space datasets comparable at the MSOA scale is challenging. However, each LAD is made up of multiple MSOAs, and it is more straight forward to aggregate Covid-19 case numbers from the MSOA scale to LAD scale (simply by addition). Case numbers can then be compared to the access to green space dataset, where LAD scale statistics are provided by the ONS. Presumably the ONS has taken an appropriate approach to translating the variables at different scale, an approach which is likely to be more sophisticated and better informed than an approach I might devise and implement. 



```{r}
format_park_cases_plot <- function(){
  list(geom_point(alpha = 0.4),
       geom_smooth(colour = "grey50", fill = "grey90"),
       theme_minimal()
       )
}
```


```{r}
p <- ggplot(data = analysis_df,
            mapping = aes(x = `Average distance to nearest Park (m)`,
                          y = log(cases_per_100000_pop))
            )

p + format_park_cases_plot()
  
```
```{r}
p <- ggplot(data = analysis_df,
            mapping = aes(x = log(`Average size of nearest Park (m2)`),
                          y = log(cases_per_100000_pop))
            )

p + format_park_cases_plot()
```
```{r}
p <- ggplot(data = analysis_df,
            mapping = aes(x = `Average number of  Parks within one km`,
                          y = log(cases_per_100000_pop))
            )

p + format_park_cases_plot()
```

```{r}
p <- ggplot(data = analysis_df,
            mapping = aes(x = log(`Average combined size of  Parks within 1km  (m2)`),
                          y = log(cases_per_100000_pop))
            )

p + format_park_cases_plot()
```

### 3.1. Private green space and case numbers


```{r}
p <- ggplot(data = analysis_df,
            mapping = aes(x = perc_garden,
                          y = log(cases_per_100000_pop))
            )

p + geom_jitter(alpha = 0.3) +
  geom_smooth() 
```


```{r}
p <- ggplot(data = analysis_df,
            mapping = aes(x = ave_garden_size,
                          y = log(cases_per_100000_pop))
            )

p + geom_jitter(alpha = 0.3) +
  geom_smooth()
```

```{r}

var_summary <- function(df, var, na.rm = TRUE) {
 
  summary <- df %>% 
    summarise(min = min({{var}}, na.rm = na.rm),
              q1 = quantile({{var}}, probs = 0.25, na.rm = na.rm),
              median = median({{var}}, na.rm = na.rm),
              q3 = quantile({{var}}, probs = 0.75, na.rm = na.rm),
              max = max({{var}}, na.rm = na.rm),
              iqr = IQR({{var}}, na.rm = na.rm),
              mean = mean({{var}}, na.rm = na.rm),
              sd = sd({{var}}, na.rm = na.rm)
              ) 
  
  summary[1, "variable"] <- toString(deparse(substitute(var)))
  summary %>% 
    relocate(variable, .before = min)
  
}

var_summary(priv_gs_focus, perc_garden)
```
